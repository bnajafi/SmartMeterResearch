{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import botocore\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AWS_ACCESS_KEY_ID = os.environ['AWS_ACCESS_KEY_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AWS_SECRET_ACCESS_KEY = os.environ['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS (S3, Redshift, Kinesis) + Databricks Spark = Real-time Smart Meter Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create S3 Bucket**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'Buckets': [{u'CreationDate': datetime.datetime(2016, 1, 26, 1, 47, 19, tzinfo=tzutc()),\n",
       "   u'Name': 'doug62890'},\n",
       "  {u'CreationDate': datetime.datetime(2015, 6, 5, 7, 3, 45, tzinfo=tzutc()),\n",
       "   u'Name': 'elasticbeanstalk-us-west-2-473548050994'},\n",
       "  {u'CreationDate': datetime.datetime(2016, 3, 7, 2, 45, 37, tzinfo=tzutc()),\n",
       "   u'Name': 'pecanstreetresearch-2016'}],\n",
       " u'Owner': {u'DisplayName': 'dkelly628',\n",
       "  u'ID': 'bda9f00a638e7c5c17498b033a6ce34b124be90c6ae542abc73a64f4d56f1913'},\n",
       " 'ResponseMetadata': {'HTTPStatusCode': 200,\n",
       "  'HostId': 'tvKe4ptiqACT0S0ZzK6+LpC36DZt2oLwSB/v8NHI7bs3smVkTQ6MkR+OQXspINn1',\n",
       "  'RequestId': 'DFAFD1582C9475BF'}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3.list_buckets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_s3_bucket(bucketname):\n",
    "    \"\"\"Quick method to create bucket with exception handling\"\"\"\n",
    "    s3 = boto3.resource('s3')\n",
    "    exists = True\n",
    "    bucket = s3.Bucket(bucketname)\n",
    "    try:\n",
    "        s3.meta.client.head_bucket(Bucket=bucketname)\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        error_code = int(e.response['Error']['Code'])\n",
    "        if error_code == 404:\n",
    "            exists = False\n",
    "    if exists:\n",
    "        print 'Bucket {} already exists'.format(bucketname)\n",
    "    else:\n",
    "        s3.create_bucket(Bucket=bucketname, GrantFullControl='dkelly628')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket pecanstreetresearch-2016 already exists\n"
     ]
    }
   ],
   "source": [
    "create_s3_bucket('pecanstreetresearch-2016')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Amazon Firehose for writing to S3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "firehose = boto3.client('firehose')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Copy Postgres to S3 via Postgres dump to CSV and s3cmd upload**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note: Used s3cmd tools because awscli tools not working in conda env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 14m rows or ~ 1.2 GB local unzipped; 10min write to CSV and another 10min to upload to S3\n",
    "# !s3cmd put ~/Users/Doug/PecanStreet/electricity-03-06-2016.csv s3://pecanstreetresearch-2016/electricity-03-06-2016.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 200k rows ~ 15 MB local unzipped; 30 sec write to CSV and 15 sec upload to S3\n",
    "# !s3cmd put ~/Users/Doug/PecanStreet/weather-03-06-2016.csv s3://pecanstreetresearch-2016/weather-03-06-2016.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Amazon Redshift: NoSQL Columnar Data Warehouse**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Quick geohashing before uploading to Redshift\n",
    "weather_df = pd.read_csv('/Users/Doug/PecanStreet/weather_03-06-2016.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>localhour</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30.292432</th>\n",
       "      <th>-97.699662</th>\n",
       "      <td>45336</td>\n",
       "      <td>45336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32.778033</th>\n",
       "      <th>-117.151885</th>\n",
       "      <td>45384</td>\n",
       "      <td>45384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40.027278</th>\n",
       "      <th>-105.256111</th>\n",
       "      <td>45384</td>\n",
       "      <td>45384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       localhour  temperature\n",
       "latitude  longitude                          \n",
       "30.292432 -97.699662       45336        45336\n",
       "32.778033 -117.151885      45384        45384\n",
       "40.027278 -105.256111      45384        45384"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df.groupby(['latitude', 'longitude']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather_df['city'] = weather_df['Austin' if weather_df.latitude=30.292432 elif '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather_df['city'] = 'city'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Austin', 'Boulder', 'San Diego'], dtype=object)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df.city.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# weather_df['city'][weather_df.latitude==40.027278] = 'Boulder'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather_df.to_csv('/Users/Doug/PecanStreet/weather_03-07-2016.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "redshift = boto3.client('redshift')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create table electricity (\n",
    "localhour timestamp not null distkey sortkey,\n",
    "dataid smallint not null,\n",
    "use\n",
    "air1\n",
    "furnace1\n",
    "car1\n",
    ");\n",
    "\n",
    "create table weather (\n",
    "localhour timestamp not null distkey sortkey,\n",
    "latitude,\n",
    "longitude,\n",
    "temperature,\n",
    ");\n",
    "\n",
    "create table households (\n",
    "dataid smallint not null distkey,\n",
    "city varchar(20) not null\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Databricks Spark Analysis: Batch analytics on S3, Streaming using Amazon Kinesis Stream**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
